---
title: "SentimentAnalysisProject"
author: "Andica, Benedicto, Cautivar"
date: "2024-12-07"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
# Reading the tweetsDF.csv file
```{r}
library(dplyr)
library(ggplot2)
library(stringr)
library(tidyverse)
library(syuzhet)
library(tm)            
library(wordcloud)     
library(RColorBrewer)
library(lubridate)

tweetsDF <- read.csv("tweetsDF.csv")
```
# Cleaning Text
```{r}
tweetsDF$text <- iconv(tweetsDF$text, from = "UTF-8", to = "ASCII//TRANSLIT", sub = "")

keywords <- "\\b(blackpink|yg|bornpink|lisa|jennie|rose|jisoo)\\b|:\\(\\(|&amp;|!|:\\(|&lt;/3|:|&lt;|/|~|iphone|android|nody_meow,|rogue_corq,|apobang27095028,|dessouslevide,|junacrawf0rd,|idkaybictdie,|lhcwesq4iebpbzf,|bpbiggestggindw,|lovemyhead,|akinsolaaliu,|nhlandmlb_fan,|virgini47003223,|angelscrown_,|stacebu,|starlight_sasha,|yuna4lifer,|diandianwong,|dillikahoshi,|tomie_jpg,|biyulving,|jshms9|1ov,|run_pjm,|lae__loner,|ariana_n64,|hdragees,|leemandelo,|purpleocean_i,|wildcatalum,|koreankrueger,|straykldswoo,|siang_ping,|lovemyheadwrap,|nyeongive,|cryptocross0ver|reexrco,|clarefl96567112,|wsbt,|killugoners,|maimechantel,|thealexateam,|ttaesthicx,|juliana62208602,|sadfuk99,|the_inspi,|hyckgasm,|hooriapashaa,|seungri_italy,|rawmilklvr,|laurettaland,|amaarzahid,|andiroo_,|__borntoslay_,|gothwolfjk,|3bbbinlove,|globalmyeon,|tianz17,|2korad,|doncastor4,|lesbi,|yolanda71545557,|mochixjm,|nunupaws,|simoncropp,|aoife,|btsvoque,|jeongpark52,|cloudychiwoo,|kaiewitherloavc,|yerimlvs,|mochixjm1,|tear_ofgod,|frothfather,|moatybuns,|richiericil,|maggiemae2019,|ckyunstd,|cyborgslament,|hyukasplush,|cxcileyyyy,|jungwoohehet,|lostinminhyuk,|crazyemio,|cbsaustin,|backtobleuside,|arches_in,|shelleypowers,|christineirishg,|bubblephehe,|minsmitten,|kaysfalling,|verrerenebi,|ntm23,|auroraluvbot,|my_drama_list,|kindordie,|kaede_zen,|luvskeehoo,"

tweetsDF$text <- tolower(tweetsDF$text)  
tweetsDF$text <- gsub("https\\S+", "", tweetsDF$text) 
tweetsDF$text <- gsub("#", "", gsub("\n", " ", tweetsDF$text)) 
tweetsDF$text <- gsub("([@?]\\S+)", "", tweetsDF$text) 
tweetsDF$text <- gsub("\\?", "", tweetsDF$text)  
tweetsDF$text <- gsub("\\b\\d{2}\\.\\d{2}\\.\\d{4}\\b", "", tweetsDF$text)  
tweetsDF$text <- gsub(keywords, "", tweetsDF$text, ignore.case = TRUE)  
tweetsDF$text <- gsub("<a href=httptwitter.comdownloadandroid rel=nofollow>twitter for android<a>", "", tweetsDF$text)
tweetsDF$text <- gsub("<a href= rel=nofollow>twitter web app<a>", "", tweetsDF$text)
tweetsDF$text <- gsub("<a href=httptwitter.comdownloadiphone rel=nofollow>twitter for iphone<a>", "", tweetsDF$text)
tweetsDF$text <- gsub("<a href=([^>]*?) rel=nofollow>([^<]*?)<a>", "", tweetsDF$text) 
tweetsDF$text <- gsub("30102022", "", tweetsDF$text)  
tweetsDF$text <- gsub("\\s+", " ", tweetsDF$text)

create_chunks <- function(df, start_row, end_row) {
  return(df[start_row:end_row, ])
}

start_row <- 1
end_row <- 1000
chunk_data <- tweetsDF[start_row:end_row, ]

chunk_data

write.csv(chunk_data, "cleaned_tweets.csv", row.names = FALSE)

write.csv(tweetsDF, "processed_tweets.csv", row.names = FALSE)

valid_texts <- chunk_data$text[chunk_data$text != ""]
cat("Number of valid texts before preprocessing: ", length(valid_texts), "\n")

if (length(valid_texts) > 0) {
  
  corpus <- Corpus(VectorSource(valid_texts))
  
  corpus <- tm_map(corpus, content_transformer(tolower))
  cat("Number of valid texts after converting to lowercase: ", length(corpus), "\n")
  
  corpus <- tm_map(corpus, removePunctuation)
  cat("Number of valid texts after removing punctuation: ", length(corpus), "\n")
  
  corpus <- tm_map(corpus, removeNumbers)
  cat("Number of valid texts after removing numbers: ", length(corpus), "\n")
  
  corpus <- tm_map(corpus, removeWords, stopwords("en"))
  cat("Number of valid texts after removing stopwords: ", length(corpus), "\n")
  
  corpus <- tm_map(corpus, stripWhitespace)
  cat("Number of valid texts after stripping whitespace: ", length(corpus), "\n")
  
  if (length(corpus) > 0) {
    wordcloud(corpus, 
              max.words = 100, 
              random.order = FALSE, 
              colors = brewer.pal(8, "Dark2"), 
              scale = c(3, 0.5))
  } else {
    cat("No valid text left to create a word cloud.\n")
  }
} else {
  cat("No valid texts available to create a word cloud.\n")
}
```

# Cleaning Dates
```{r}
tweetsDF$Created_At_Round <- as.POSIXct(tweetsDF$Created_At_Round, format = "%d/%m/%Y %H:%M", tz = "UTC")

tweetsDF$date <- as.Date(tweetsDF$Created_At_Round)
tweetsDF$hour <- format(tweetsDF$Created_At_Round, "%H")

hourly_tweets <- tweetsDF %>%
  group_by(date, hour) %>%
  summarise(tweet_count = n(), .groups = "drop") %>%
  mutate(hour = as.numeric(hour))

plots <- lapply(unique(hourly_tweets$date), function(current_date) {
  # Filter data for the current date
  date_data <- hourly_tweets %>% 
    filter(date == current_date)
  
  ggplot(date_data, aes(x = hour, y = tweet_count)) +
    geom_line(color = "blue", linewidth = 1) +
    geom_point(color = "red") +
    geom_text(aes(label = tweet_count), vjust = -0.5, color = "black", size = 3) +
    scale_x_continuous(breaks = 0:23) +
    labs(
      title = paste("Tweet Counts on", format(current_date, "%B %d, %Y")),
      x = "Hour of the Day",
      y = "Number of Tweets"
    ) +
    theme_minimal() +
    theme(axis.text.x = element_text(angle = 45, hjust = 1))
})

for(i in seq_along(plots)) {
  print(plots[[i]])
}

summary_per_date <- tweetsDF %>%
  group_by(date) %>%
  summarise(
    total_tweets = n(),
    unique_hours = n_distinct(format(Created_At_Round, "%H"))
  )
print(summary_per_date)


```
# The time series graph provides a comprehensive visualization of tweet activity across a single day, displaying the number of tweets for each hour from 0 to 23. Represented by a blue line with red points, the graph offers a granular view of tweet distribution throughout the day. By showcasing the exact tweet count through black text labels, it reveals the hourly fluctuations in social media engagement. The visualization allows for quick insights into peak activity periods and less active hours, potentially highlighting the daily rhythm of tweet interactions.
#When analyzing the graph, one can observe the subtle nuances of tweet patterns. The peaks and valleys in the line graph might correspond to specific times of day when users are more likely to be active, such as morning commutes, lunch breaks, or evening leisure time. These patterns could be influenced by factors like work schedules, current events, or the nature of the specific topic or community being analyzed. The graph transforms raw numerical data into a visually intuitive representation, making it easier to understand the temporal dynamics of tweet frequency and identify potential trends or anomalies in social media activity.


# Cleaning the StatucSource Column
```{r}
tweetsDF$statusSource_clean <- gsub("<.*?>", "", tweetsDF$statusSource)

statusCounts <- table(tweetsDF$statusSource_clean)

barplot(statusCounts, 
        main = "Tweet Source Distribution", 
        xlab = "Platform", 
        ylab = "Number of Tweets", 
        col = rainbow(length(statusCounts)), 
        las = 2,              
        cex.axis = 0.15)         
```
#The first graph, a bar plot, illustrates the distribution of tweets across various source platforms. It reveals a highly skewed pattern, where a small number of dominant platforms, such as Twitter for iPhone and Twitter for Android, contribute the majority of tweets. Meanwhile, most other sources show minimal tweet counts. This emphasizes the significant role mainstream platforms play in driving Twitter activity, while less prominent sources have little impact on overall tweet volumes.






# Compare Platforms over-time
```{r}
tweetsDF$Created_At_Round <- as.Date(tweetsDF$Created_At_Round)

platformTimeSeries <- table(tweetsDF$Created_At_Round, tweetsDF$statusSource_clean)

platformTimeSeriesDF <- as.data.frame(platformTimeSeries)

library(tidyr)
platformTimeSeriesReshaped <- platformTimeSeriesDF %>%
  pivot_wider(names_from = Var2, values_from = Freq, values_fill = list(Freq = 0))

platformTimeSeriesReshaped$Var1 <- as.Date(platformTimeSeriesReshaped$Var1)

all_dates <- seq(min(platformTimeSeriesReshaped$Var1), max(platformTimeSeriesReshaped$Var1), by = "day")
platformTimeSeriesReshaped <- merge(platformTimeSeriesReshaped, data.frame(Var1 = all_dates), by = "Var1", all = TRUE)

library(reshape2)
platformTimeSeriesLong <- melt(platformTimeSeriesReshaped, id.vars = "Var1", variable.name = "Platform", value.name = "TweetCount")

library(ggplot2)
ggplot(platformTimeSeriesLong, aes(x = Var1, y = TweetCount, color = Platform)) +
  geom_line() +
  labs(x = "Date", y = "Number of Tweets", title = "Tweets by Platform Over Time") +
  theme_minimal() +
  theme(legend.title = element_blank())

```


#The second graph provides a detailed list of the various platforms and apps used as tweet sources. It highlights the extensive diversity of tools integrated with Twitter, including both popular and niche platforms. The presence of many low-contribution sources suggests that some are specialized tools or automated systems (bots) with limited activity. This diversity showcases Twitter's versatility in accommodating a wide range of users and applications, from casual users to businesses leveraging automated posting tools.






# Chunk of Codes for Cleaning and Making an Graph about the TweetSource(Iphone, Android, others etc.)
```{r}
library(ggplot2)
library(readr)
library(dplyr)

print(colnames(tweetsDF))
```

```{r}
TweetSourceCounts <- tweetsDF %>%
  group_by(tweetSource) %>%
  summarize(Count = n()) %>%
  arrange(desc(Count))

TweetSourceCounts$tweetSource <- factor(TweetSourceCounts$tweetSource, 
                                          levels = TweetSourceCounts$tweetSource)


ggplot(TweetSourceCounts, aes(x = reorder(tweetSource, -Count), y = Count, fill = tweetSource)) +
  geom_bar(stat = "identity") +
  labs(title = "Tweet Source Comparison",
       x = "Tweet Source",
       y = "Count") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  scale_fill_manual(values = c("iphone" = "red", "android" = "orange", "others" = "yellow", "ipad" = "blue", "ifttt" = "green", "dlvr.it" = "violet"))
```

# The graph titled "Tweet Source Comparison" illustrates the distribution of tweets based on their source. The majority of tweets are posted using iPhone and Android, which dominate the chart with the highest counts. These two sources significantly outperform others, highlighting their widespread use among Twitter users. The third most common source is categorized as Others, though its count is notably lower compared to iPhone and Android. Meanwhile, platforms like iPad, ifttt, and dlvr.it contribute only a small fraction of tweets, indicating limited usage.

# This distribution suggests that mobile devices, particularly iPhones and Android smartphones, are the primary tools for engaging on Twitter. The "Others" category likely represents a mix of niche or less common platforms. Automated tools like ifttt and dlvr.it are used sparingly, possibly for specific purposes such as scheduled or automated posts. Businesses and marketers looking to target Twitter users should prioritize strategies that cater to mobile users, particularly those on iPhone and Android devices, given their overwhelming share. Further analysis of the "Others" category might reveal additional insights about underutilized platforms or unique user behaviors.

```{r}


tweetsDF$sentiment <- get_sentiment(tweetsDF$text, method = "syuzhet")

tweetsDF <- tweetsDF %>%
  mutate(sentiment_category = case_when(
    sentiment > 0 ~ "Positive",
    sentiment == 0 ~ "Neutral",
    sentiment < 0 ~ "Negative"
  ))
sentiment_by_source <- tweetsDF %>%
  group_by(tweetSource, sentiment_category) %>%
  summarize(count = n(), .groups = 'drop')

ggplot(sentiment_by_source, aes(x = tweetSource, y = count, fill = sentiment_category)) +
  geom_bar(stat = "identity", position = "dodge") +
  labs(
    title = "Sentiment Distribution by Tweet Source",
    x = "Tweet Source",
    y = "Number of Tweets",
    fill = "Sentiment Category"
  ) +
  theme_minimal()
```
# The grouped bar chart provides valuable insights into the sentiment distribution of tweets across different sources, such as iPhone, Android, and other platforms. By examining the chart, we can observe which sentiment is most dominant for each tweet source. For example, tweets from platforms like "iPhone" may have a higher proportion of Positive sentiment, while sources like "Android" could show a mix of Positive, Neutral, and Negative sentiments. This variation suggests that sentiment trends differ across platforms. Additionally, the chart reveals the volume of tweets per source, highlighting how certain platforms, like iPhone, generate more tweets compared to others like "dlvr.it" or "IFTTT". This discrepancy may indicate the popularity of certain sources. From a strategic standpoint, understanding these sentiment trends can be crucial for businesses or analysts, as positive sentiments could indicate more favorable user engagement, while negative sentiments from specific sources may signal user dissatisfaction or areas for improvement. Overall, the graph helps in recognizing patterns that can inform marketing strategies, customer engagement, and platform-related decision-making.
